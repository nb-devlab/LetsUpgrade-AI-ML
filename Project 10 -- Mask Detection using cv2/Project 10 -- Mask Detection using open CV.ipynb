{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__importing basic packages__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-28T11:53:06.470615Z",
     "start_time": "2021-05-28T11:52:28.033124Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib as mt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-28T11:54:06.895419Z",
     "start_time": "2021-05-28T11:53:06.482589Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.5.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-28T12:06:08.421884Z",
     "start_time": "2021-05-28T12:06:08.357882Z"
    }
   },
   "outputs": [],
   "source": [
    "import cv2, os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-28T12:06:08.986745Z",
     "start_time": "2021-05-28T12:06:08.427888Z"
    }
   },
   "outputs": [],
   "source": [
    "# Preprocessing could include resize, nomalization, augmentation, changing color space, smoothening the images, morphological transfer, dilation & erosion\n",
    "\n",
    "#In this case using - ImageDataGenerator -- for data augmentation\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "from keras.layers import Conv2D, Input, ZeroPadding2D\n",
    "from keras.layers import BatchNormalization, Activation, MaxPooling2D\n",
    "from keras.layers import Flatten, Dense, Dropout\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.models import Model, load_model\n",
    "from keras.metrics import Accuracy\n",
    "from keras import utils\n",
    "from keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-28T12:06:09.000666Z",
     "start_time": "2021-05-28T12:06:08.993668Z"
    }
   },
   "outputs": [],
   "source": [
    "# import imutils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-28T12:06:09.125387Z",
     "start_time": "2021-05-28T12:06:09.009671Z"
    }
   },
   "outputs": [],
   "source": [
    "# defining various augmentation properties\n",
    "train_datagen = ImageDataGenerator(rotation_range=40, width_shift_range=0.2, height_shift_range=0.2, rescale=1./255, shear_range=0.2, zoom_range=0.2, horizontal_flip=True, fill_mode='nearest')\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-28T12:06:09.655164Z",
     "start_time": "2021-05-28T12:06:09.131367Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1376 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# dividing the total number of models into batches\n",
    "batch_size=10\n",
    "\n",
    "# Reading the train directory images\n",
    "train_data = train_datagen.flow_from_directory('C:/Users/comp/Python Coding/LU AI-ML/Project 10 -- Mask Detection using open CV/data/train', target_size=(100,100), batch_size=batch_size, class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-28T12:06:10.103783Z",
     "start_time": "2021-05-28T12:06:09.662151Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 194 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# Reading the test directory images\n",
    "\n",
    "test_data = test_datagen.flow_from_directory('C:/Users/comp/Python Coding/LU AI-ML/Project 10 -- Mask Detection using open CV/data/test', target_size=(100,100), batch_size=batch_size, class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-28T12:06:12.885435Z",
     "start_time": "2021-05-28T12:06:10.109799Z"
    }
   },
   "outputs": [],
   "source": [
    "# CNN model architechture\n",
    "\n",
    "model = Sequential(\n",
    "    [Conv2D(100,(3,3), activation='relu', input_shape = (100,100,3)), MaxPooling2D(2,2),\n",
    "     Conv2D(100,(3,3), activation='relu'), MaxPooling2D(2,2),\n",
    "     Flatten(),\n",
    "     Dropout(0.5),\n",
    "     Dense(50, activation='relu'),\n",
    "     Dense(2, activation='softmax')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-28T12:06:12.925440Z",
     "start_time": "2021-05-28T12:06:12.896443Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 98, 98, 100)       2800      \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 49, 49, 100)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 47, 47, 100)       90100     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 23, 23, 100)       0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 52900)             0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 52900)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 50)                2645050   \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2)                 102       \n",
      "=================================================================\n",
      "Total params: 2,738,052\n",
      "Trainable params: 2,738,052\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-28T12:06:13.094652Z",
     "start_time": "2021-05-28T12:06:12.935441Z"
    }
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['acc'])\n",
    "# using sparse_categorical_crossentropy instead of binary_crossentropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-28T12:08:27.694598Z",
     "start_time": "2021-05-28T12:06:13.101574Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\comp\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py:1915: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "5/5 [==============================] - 60s 2s/step - loss: 1.4017 - acc: 0.4594 - val_loss: 0.7381 - val_acc: 0.4500\n",
      "Epoch 2/10\n",
      "5/5 [==============================] - 8s 2s/step - loss: 0.6897 - acc: 0.5061 - val_loss: 0.6956 - val_acc: 0.4500\n",
      "Epoch 3/10\n",
      "5/5 [==============================] - 8s 2s/step - loss: 0.6927 - acc: 0.4781 - val_loss: 0.6438 - val_acc: 0.6500\n",
      "Epoch 4/10\n",
      "5/5 [==============================] - 7s 1s/step - loss: 0.7001 - acc: 0.4369 - val_loss: 0.6667 - val_acc: 0.5500\n",
      "Epoch 5/10\n",
      "5/5 [==============================] - 7s 1s/step - loss: 0.6714 - acc: 0.5789 - val_loss: 0.6271 - val_acc: 0.6500\n",
      "Epoch 6/10\n",
      "5/5 [==============================] - 7s 1s/step - loss: 0.6720 - acc: 0.5789 - val_loss: 0.6796 - val_acc: 0.4500\n",
      "Epoch 7/10\n",
      "5/5 [==============================] - 8s 2s/step - loss: 0.6586 - acc: 0.5467 - val_loss: 0.6725 - val_acc: 0.4500\n",
      "Epoch 8/10\n",
      "5/5 [==============================] - 8s 2s/step - loss: 0.6734 - acc: 0.4194 - val_loss: 0.6129 - val_acc: 0.5000\n",
      "Epoch 9/10\n",
      "5/5 [==============================] - 8s 2s/step - loss: 0.6092 - acc: 0.6100 - val_loss: 0.5645 - val_acc: 0.7000\n",
      "Epoch 10/10\n",
      "5/5 [==============================] - 7s 1s/step - loss: 0.6250 - acc: 0.6364 - val_loss: 0.5235 - val_acc: 0.6750\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "\n",
    "history = model.fit_generator(train_data, steps_per_epoch=50//batch_size, epochs=10, validation_data=test_data, validation_steps=40//batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-28T12:08:28.655318Z",
     "start_time": "2021-05-28T12:08:27.700606Z"
    }
   },
   "outputs": [],
   "source": [
    "# Save the model\n",
    "model.save('face_mask.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-28T12:08:29.238300Z",
     "start_time": "2021-05-28T12:08:28.658308Z"
    }
   },
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model('face_mask.h5')\n",
    "\n",
    "result = {0:'wihtout mask', 1:'with mask'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-28T12:08:29.253305Z",
     "start_time": "2021-05-28T12:08:29.243304Z"
    }
   },
   "outputs": [],
   "source": [
    "gr_dict = {0:(0,0,255), 1:(0,255,0)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-28T12:08:29.403663Z",
     "start_time": "2021-05-28T12:08:29.268308Z"
    }
   },
   "outputs": [],
   "source": [
    "rect_size = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-28T12:08:31.241029Z",
     "start_time": "2021-05-28T12:08:29.408665Z"
    }
   },
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-28T12:08:31.659189Z",
     "start_time": "2021-05-28T12:08:31.254028Z"
    }
   },
   "outputs": [],
   "source": [
    "haarcascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-28T12:12:34.612202Z",
     "start_time": "2021-05-28T12:12:34.328198Z"
    }
   },
   "outputs": [],
   "source": [
    "while True:\n",
    "    r,im = cap.read()\n",
    "    im = cv2.flip(im,1,1)\n",
    "    # resize\n",
    "    r_size = cv2.resize(im, (im.shape[1]//rect_size, im.shape[0]//rect_size))\n",
    "    face = haarcascade.detectMultiScale(r_size)\n",
    "    \n",
    "    for i in face:\n",
    "        (x,y,w,h) = [v * rect_size for v in i]\n",
    "        face_img = im[y:y+h, x:x+w]\n",
    "        r_size = cv2.resize(face_img, (100,100))\n",
    "        normalize = r_size/255.0\n",
    "        reshaped_img = np.reshape(normalize, (1,100,100,3))\n",
    "        reshaped_img = np.vstack([reshaped_img])\n",
    "        result = model.predict(reshaped_img)\n",
    "        label = np.argmax(result, axis=1)[0]\n",
    "        cv2.rectangle(im, (x,y), (x+w, y+h), gr_dict[label], 2)\n",
    "        cv2.rectangle(im, (x, y-40), (x+w, y), gr_dict[label], -1)\n",
    "        #cv2.putText(im, result[label], (x, y-10), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255,255,255), 2)\n",
    "    cv2.imshow('Recording', im)\n",
    "    key=cv2.waitKey(10)\n",
    "    if key == 27:\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
